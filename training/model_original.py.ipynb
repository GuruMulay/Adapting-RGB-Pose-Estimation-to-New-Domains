{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Activation, Input, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Multiply\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import random_normal, constant\n",
    "\n",
    "stages = 6\n",
    "# original cpm with COCO\n",
    "np_branch1 = 38\n",
    "np_branch2 = 19\n",
    "\n",
    "def relu(x): return Activation('relu')(x)\n",
    "\n",
    "def conv(x, nf, ks, name, weight_decay):\n",
    "    kernel_reg = l2(weight_decay[0]) if weight_decay else None\n",
    "    bias_reg = l2(weight_decay[1]) if weight_decay else None\n",
    "\n",
    "    x = Conv2D(nf, (ks, ks), padding='same', name=name,\n",
    "               kernel_regularizer=kernel_reg,\n",
    "               bias_regularizer=bias_reg,\n",
    "               kernel_initializer=random_normal(stddev=0.01),\n",
    "               bias_initializer=constant(0.0))(x)\n",
    "    return x\n",
    "\n",
    "def pooling(x, ks, st, name):\n",
    "    x = MaxPooling2D((ks, ks), strides=(st, st), name=name)(x)\n",
    "    return x\n",
    "\n",
    "def vgg_block(x, weight_decay):\n",
    "    # Block 1\n",
    "    x = conv(x, 64, 3, \"conv1_1\", (weight_decay, 0))  # Assign_22\n",
    "    x = relu(x)\n",
    "    x = conv(x, 64, 3, \"conv1_2\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = pooling(x, 2, 2, \"pool1_1\")\n",
    "\n",
    "    # Block 2\n",
    "    x = conv(x, 128, 3, \"conv2_1\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 3, \"conv2_2\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = pooling(x, 2, 2, \"pool2_1\")\n",
    "\n",
    "    # Block 3\n",
    "    x = conv(x, 256, 3, \"conv3_1\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 256, 3, \"conv3_2\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 256, 3, \"conv3_3\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 256, 3, \"conv3_4\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = pooling(x, 2, 2, \"pool3_1\")\n",
    "\n",
    "    # Block 4\n",
    "    x = conv(x, 512, 3, \"conv4_1\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 512, 3, \"conv4_2\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "\n",
    "    # Additional non vgg layers\n",
    "    x = conv(x, 256, 3, \"conv4_3_CPM\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 3, \"conv4_4_CPM\", (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def stage1_block(x, num_p, branch, weight_decay):\n",
    "    # Block 1\n",
    "    x = conv(x, 128, 3, \"Mconv1_stage1_L%d\" % branch, (weight_decay, 0))  # Assign_40\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 3, \"Mconv2_stage1_L%d\" % branch, (weight_decay, 0))  # _36\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 3, \"Mconv3_stage1_L%d\" % branch, (weight_decay, 0))  # _32\n",
    "    x = relu(x)\n",
    "    x = conv(x, 512, 1, \"Mconv4_stage1_L%d\" % branch, (weight_decay, 0))  # _28\n",
    "    x = relu(x)\n",
    "    x = conv(x, num_p, 1, \"Mconv5_stage1_L%d_EGGNOG\" % branch, (weight_decay, 0))  # _26\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def stageT_block(x, num_p, stage, branch, weight_decay):\n",
    "    # Block 1\n",
    "    x = conv(x, 128, 7, \"Mconv1_stage%d_L%d_E\" % (stage, branch), (weight_decay, 0))  # _24\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 7, \"Mconv2_stage%d_L%d\" % (stage, branch), (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 7, \"Mconv3_stage%d_L%d\" % (stage, branch), (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 7, \"Mconv4_stage%d_L%d\" % (stage, branch), (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 7, \"Mconv5_stage%d_L%d\" % (stage, branch), (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, 128, 1, \"Mconv6_stage%d_L%d\" % (stage, branch), (weight_decay, 0))\n",
    "    x = relu(x)\n",
    "    x = conv(x, num_p, 1, \"Mconv7_stage%d_L%d_EGGNOG\" % (stage, branch), (weight_decay, 0))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def apply_mask(x, mask1, mask2, num_p, stage, branch):\n",
    "    w_name = \"weight_stage%d_L%d\" % (stage, branch)\n",
    "    if num_p == np_branch1:\n",
    "        w = Multiply(name=w_name)([x, mask1])  # vec_weight\n",
    "    elif num_p == np_branch2:\n",
    "        w = Multiply(name=w_name)([x, mask2])  # vec_heat\n",
    "    else:\n",
    "        assert False, \"wrong number of layers num_p=%d \" % num_p\n",
    "    return w\n",
    "\n",
    "\n",
    "def get_training_model_eggnog(weight_decay, gpus=None):\n",
    "    \n",
    "    img_input_shape = (None, None, 3)\n",
    "    # to print the shapes at the output of every layer\n",
    "    # img_input_shape = (240, 320, 3)\n",
    "    \n",
    "    # don't have these masks in EGGNOG\n",
    "    # vec_input_shape = (None, None, 36)  # 36 pafs \n",
    "    # heat_input_shape = (None, None, 20)  # 20 heatmaps\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    img_input = Input(shape=img_input_shape)\n",
    "    # don't have these masks in EGGNOG\n",
    "    # vec_weight_input = Input(shape=vec_input_shape)\n",
    "    # heat_weight_input = Input(shape=heat_input_shape)\n",
    "\n",
    "    inputs.append(img_input)\n",
    "    # don't have these masks in EGGNOG\n",
    "    # inputs.append(vec_weight_input)\n",
    "    # inputs.append(heat_weight_input)\n",
    "\n",
    "    img_normalized = Lambda(lambda x: x / 256 - 0.5)(img_input)  # [-0.5, 0.5]\n",
    "\n",
    "    # VGG\n",
    "    stage0_out = vgg_block(img_normalized, weight_decay)\n",
    "\n",
    "    # stage 1 - branch 1 (PAF)\n",
    "    stage1_branch1_out = stage1_block(stage0_out, np_branch1, 1, weight_decay)\n",
    "    # don't have to apply masks becuase eggnog has everything labeled and only one person per frame\n",
    "    # w1 = apply_mask(stage1_branch1_out, vec_weight_input, heat_weight_input, np_branch1, 1, 1)\n",
    "\n",
    "    # stage 1 - branch 2 (confidence maps)\n",
    "    stage1_branch2_out = stage1_block(stage0_out, np_branch2, 2, weight_decay)\n",
    "    # don't have to apply masks becuase eggnog has everything labeled and only one person per frame\n",
    "    # w2 = apply_mask(stage1_branch2_out, vec_weight_input, heat_weight_input, np_branch2, 1, 2)\n",
    "\n",
    "    x = Concatenate()([stage1_branch1_out, stage1_branch2_out, stage0_out])\n",
    "\n",
    "    # don't have to apply masks becuase eggnog has everython labeled and only one person per frame\n",
    "    # outputs.append(w1)\n",
    "    # outputs.append(w2)\n",
    "    \n",
    "    outputs.append(stage1_branch1_out)\n",
    "    outputs.append(stage1_branch2_out)\n",
    "\n",
    "    # stage sn >= 2\n",
    "    for sn in range(2, stages + 1):\n",
    "        # stage SN - branch 1 (PAF)\n",
    "        stageT_branch1_out = stageT_block(x, np_branch1, sn, 1, weight_decay)\n",
    "        # don't have to apply masks becuase eggnog has everything labeled and only one person per frame\n",
    "        # w1 = apply_mask(stageT_branch1_out, vec_weight_input, heat_weight_input, np_branch1, sn, 1)\n",
    "\n",
    "        # stage SN - branch 2 (confidence maps)\n",
    "        stageT_branch2_out = stageT_block(x, np_branch2, sn, 2, weight_decay)\n",
    "        # don't have to apply masks becuase eggnog has everything labeled and only one person per frame\n",
    "        # w2 = apply_mask(stageT_branch2_out, vec_weight_input, heat_weight_input, np_branch2, sn, 2)\n",
    "\n",
    "        # don't have to apply masks becuase eggnog has everything labeled and only one person per frame\n",
    "        # outputs.append(w1)\n",
    "        # outputs.append(w2)\n",
    "        \n",
    "        outputs.append(stageT_branch1_out)\n",
    "        outputs.append(stageT_branch2_out)\n",
    "\n",
    "        if (sn < stages):\n",
    "            x = Concatenate()([stageT_branch1_out, stageT_branch2_out, stage0_out])\n",
    "\n",
    "    if gpus is None:\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "    else:\n",
    "        import tensorflow as tf\n",
    "        with tf.device('/cpu:0'): #this model will not be actually used, it's template\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_training_model_original(weight_decay, gpus=None):\n",
    "\n",
    "    img_input_shape = (None, None, 3)\n",
    "    vec_input_shape = (None, None, 38)\n",
    "    heat_input_shape = (None, None, 19)\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    img_input = Input(shape=img_input_shape)\n",
    "    vec_weight_input = Input(shape=vec_input_shape)\n",
    "    heat_weight_input = Input(shape=heat_input_shape)\n",
    "\n",
    "    inputs.append(img_input)\n",
    "    inputs.append(vec_weight_input)\n",
    "    inputs.append(heat_weight_input)\n",
    "\n",
    "    img_normalized = Lambda(lambda x: x / 256 - 0.5)(img_input)  # [-0.5, 0.5]\n",
    "\n",
    "    # VGG\n",
    "    stage0_out = vgg_block(img_normalized, weight_decay)\n",
    "\n",
    "    # stage 1 - branch 1 (PAF)\n",
    "    stage1_branch1_out = stage1_block(stage0_out, np_branch1, 1, weight_decay)\n",
    "    w1 = apply_mask(stage1_branch1_out, vec_weight_input, heat_weight_input, np_branch1, 1, 1)\n",
    "\n",
    "    # stage 1 - branch 2 (confidence maps)\n",
    "    stage1_branch2_out = stage1_block(stage0_out, np_branch2, 2, weight_decay)\n",
    "    w2 = apply_mask(stage1_branch2_out, vec_weight_input, heat_weight_input, np_branch2, 1, 2)\n",
    "\n",
    "    x = Concatenate()([stage1_branch1_out, stage1_branch2_out, stage0_out])\n",
    "\n",
    "    outputs.append(w1)\n",
    "    outputs.append(w2)\n",
    "\n",
    "    # stage sn >= 2\n",
    "    for sn in range(2, stages + 1):\n",
    "        # stage SN - branch 1 (PAF)\n",
    "        stageT_branch1_out = stageT_block(x, np_branch1, sn, 1, weight_decay)\n",
    "        w1 = apply_mask(stageT_branch1_out, vec_weight_input, heat_weight_input, np_branch1, sn, 1)\n",
    "\n",
    "        # stage SN - branch 2 (confidence maps)\n",
    "        stageT_branch2_out = stageT_block(x, np_branch2, sn, 2, weight_decay)\n",
    "        w2 = apply_mask(stageT_branch2_out, vec_weight_input, heat_weight_input, np_branch2, sn, 2)\n",
    "\n",
    "        outputs.append(w1)\n",
    "        outputs.append(w2)\n",
    "\n",
    "        if (sn < stages):\n",
    "            x = Concatenate()([stageT_branch1_out, stageT_branch2_out, stage0_out])\n",
    "\n",
    "    if gpus is None:\n",
    "        model = Model(inputs=inputs, outputs=outputs)\n",
    "    else:\n",
    "        import tensorflow as tf\n",
    "        with tf.device('/cpu:0'):  # this model will not be actually used, it's template\n",
    "            model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
